services:
  atlas-worker:
    build: 
      context: .
      args:
        GPU_BACKEND: ${GPU_BACKEND:-cuda}
    container_name: atlas-worker
    restart: unless-stopped
    network_mode: host
    
    # GPU support (NVIDIA/CUDA only - remove this block for Apple Silicon/Metal)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Persistent volumes
    volumes:
      - models:/models
      - openclaw-config:/root/.openclaw
    
    # Environment variables
    environment:
      - ATLAS_GATEWAY_HOST=${ATLAS_GATEWAY_HOST:-atlas}
      - ATLAS_GATEWAY_PORT=${ATLAS_GATEWAY_PORT:-18789}
      - WORKER_NAME=${WORKER_NAME:-}
      - ATLAS_GATEWAY_TOKEN=${ATLAS_GATEWAY_TOKEN:-}
      - MODEL_NAME=${MODEL_NAME:-}
      - LLAMA_GPU_LAYERS=${LLAMA_GPU_LAYERS:-99}
      - LLAMA_CTX_SIZE=${LLAMA_CTX_SIZE:-8192}
      - LLAMA_PORT=${LLAMA_PORT:-8080}
      - GPU_BACKEND=${GPU_BACKEND:-cuda}

volumes:
  models:
    driver: local
  openclaw-config:
    driver: local